{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Denoising task",
      "provenance": [],
      "collapsed_sections": [
        "qc7BJnQF8zam"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP9RZak/pu40vEZf7xy3GGf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamba124/just_for_fun/blob/classifier-in-autoenc/Denoising_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hyWYiPqLdez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Из кераса загружаем необходимые слои для нейросети\n",
        "import tensorflow.keras.layers as layers\n",
        "from tensorflow.keras import backend as K # подтягиваем базовые керасовские функции\n",
        "from tensorflow.keras.optimizers import Adam # загружаем выбранный оптимизатор\n",
        "from tensorflow.keras import utils # загружаем утилиты кераса\n",
        "from google.colab import files # модуль для загрузки файлов в colab\n",
        "import matplotlib.pyplot as plt # из библиотеки для визуализации данных возьмём интерфейс для построения графиков простых функций\n",
        "from tensorflow.keras.preprocessing import image # модуль для отрисовки изображения\n",
        "import numpy as np # библиотека для работы с массивами данных\n",
        "import librosa #Параметризация аудио\n",
        "import os \n",
        "\n",
        "import pandas as pd # библиотека для анализа и обработки данных\n",
        "from PIL import Image # модуль для отрисовки изображения\n",
        "from sklearn.model_selection import train_test_split # модуль для разбивки выборки на тренировочную/тестовую\n",
        "from sklearn.preprocessing import StandardScaler # модуль для стандартизации данных\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model #из кераса подгружаем абстрактный класс базовой модели, метод загрузки предобученной модели\n",
        "from tensorflow.keras.optimizers import RMSprop #из кераса загружаем выбранный оптимизатор"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc7BJnQF8zam",
        "colab_type": "text"
      },
      "source": [
        "#Автокодировщик"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZAiEuYx899D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baseAutoencoder(): # зададим функцию создания базового автокодировщика\n",
        "    img_input = Input((28,28,1)) # задаём входные размеры\n",
        "\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(img_input) # входные данные передаем на слой двумерной свёртки\n",
        "    x = BatchNormalization()(x) # затем пропускаем через слой нормализации данных \n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x) # далее снова слой двумерной свёртки\n",
        "    x = BatchNormalization()(x) # и еще слой нормализации данных\n",
        "    x = MaxPooling2D()(x) # передаём на слой подвыборки, снижающий размерность поступивших на него данных\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x) # передаем на слой двумерной свёртки\n",
        "    x = BatchNormalization()(x) # пропускаем через слой нормализации данных \n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)  # далее снова слой двумерной свёртки\n",
        "    x = BatchNormalization()(x) # и еще слой нормализации данных\n",
        "    x = MaxPooling2D()(x) # передаём на слой подвыборки\n",
        "    # Изображение ужали до 7*7\n",
        "\n",
        "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', activation='relu')(x) # слой разжимает данные(с 7*7 на 14*14)\n",
        "    x = BatchNormalization()(x) # слой нормализации данных\n",
        "    \n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x) # передаем на слой двумерной свёртки\n",
        "    x = BatchNormalization()(x) # слой нормализации данных\n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x) # ещё слой двумерной свёртки\n",
        "    x = BatchNormalization()(x) # слой нормализации данных\n",
        "    # Сжатие MaxPooling2D не применяем\n",
        "\n",
        "    x = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', activation='relu')(x) # слой разжимает данные(с 14*14 на 28*28)\n",
        "    x = BatchNormalization()(x) # слой нормализации данных\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x) # передаем на слой двумерной свёртки\n",
        "    x = BatchNormalization()(x) # слой нормализации данных\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x) # ещё слой двумерной свёртки\n",
        "    x = BatchNormalization()(x) # слой нормализации данных\n",
        "\n",
        "    # Финальный слой двумерной свертки, выдающий итоговое изображение\n",
        "    x = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    model = Model(img_input, x) # указываем модель, с оригинальным изображением на входе в сеть и сжатым-разжатым на выходе из сети\n",
        "    model.compile(optimizer=Adam(),\n",
        "                  loss='mean_squared_error') # компилируем модель с оптимайзером Адам и среднеквадратичной ошибкой\n",
        "\n",
        "    return model # функция вернёт заданную модель"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHiC0JfNKHUH",
        "colab_type": "text"
      },
      "source": [
        "# AUDIO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upG9nFePiCol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "59d91346-0039-4cef-fb9f-4404145f18cf"
      },
      "source": [
        "!pip install soundfile"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9ZoO27AcEQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa # for mel-spectrogram estimation\n",
        "import soundfile # for opening .flac audio\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQn16lh2cEQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalized log-mel-spectrogram of clean and noisy audios\n",
        "clean_mel = 1 + np.log(1.e-12 + librosa.feature.melspectrogram(clean_audio, sr=framerate, n_fft=1024, hop_length=256, fmin=20, fmax=8000, n_mels=80)).T / 10.\n",
        "noisy_mel = 1 + np.log(1.e-12 + librosa.feature.melspectrogram(noisy_audio, sr=framerate, n_fft=1024, hop_length=256, fmin=20, fmax=8000, n_mels=80)).T / 10."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdCYF5-wcEQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_audio, framerate = soundfile.read('20-205-0001.flac')\n",
        "noisy_audio, framerate = soundfile.read('20-205-0000_noisy.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g957MMEVcEQn",
        "colab_type": "code",
        "outputId": "4892b7dd-a2e1-4357-b6c2-8ce2815c1162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def get_chunks(signal, length, step):\n",
        "  batch =[]\n",
        "  syms_len = len(signal)\n",
        "  index = 0\n",
        "  \n",
        "  while (index + length <= syms_len):\n",
        "    batch.append(signal[index:index+length])\n",
        "    index += step\n",
        "\n",
        "  return batch\n",
        "\n",
        "def prepare_chunks(audio, len , step):\n",
        "  batch_list = []\n",
        "  for item in audio:\n",
        "    batch_list.append(get_chunks(item))\n",
        "\n",
        "  return np.array(batch_list)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.85\n",
            "11.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD6WaJitJFgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folders = os.listdir('/content/drive/My Drive/train')\n",
        "clean_arrays = []\n",
        "noisy_arrays = []\n",
        "\n",
        "for folder in folders:\n",
        "  patch = os.listdir(folder)\n",
        "  for arr in patch:\n",
        "    clean_arrays.append(np.load(folders+'clean'+folder+arr))\n",
        "    noisy_arrays.append(np.load(folders+'noisy'+folder+arr))\n",
        "\n",
        "clean_arrays_ = []\n",
        "noisy_arrays_ = []\n",
        "\n",
        "for i in range(len(clean_arrays)):\n",
        "  clean_arrays_ = [arr for arr in clean_arrays[i]]\n",
        "  noisy_arrays_ = [arr for arr in noisy_arrays[i]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47SaACdAictt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c9d96d7f-c16c-4a23-8e27-af35cabff337"
      },
      "source": [
        "length = 60 \n",
        "step = 25\n",
        "\n",
        "x_train = prepare_chunks(clean_arrays_, length, step)\n",
        "y_train = np.ones(x_train.shape)\n",
        "\n",
        "x_val = prepare_chunks(noisy_arrays_, length, step)\n",
        "y_val = np.zeros(x_train.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.47001022, -0.46614806, -0.46428758, ...,  1.47169741,\n",
              "        1.47291896,  1.479164  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkeN5CipkRlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classificator(vector):\n",
        "  shape_ = (vector.shape[1],vector.shape[2])\n",
        "  inputs = layers.Input(shape = shape_)\n",
        "  hidden = layers.Conv1D(8, 3)(inputs)\n",
        "  hidden = layers.Activation('tanh')(hidden)\n",
        "\n",
        "  hidden = layers.Flatten()(hidden)\n",
        "  hidden = layers.Dense(56)(hidden)\n",
        "  hidden = layers.Activation('relu')(hidden)\n",
        "\n",
        "  hidden = layers.Dense(100)(hidden)\n",
        "  out = layers.Dense(1, activation = 'sigmoid')(hidden)\n",
        "  \n",
        "  model = Model(inputs = inputs, outputs = out)\n",
        "\n",
        "  return model\n",
        "\n",
        "def autoencoder(model, vector):\n",
        "  #result = model.predict(vector)\n",
        "  inputs_decision = layers.Input(shape = (1,))\n",
        "  inputs_vector = layers.Input(shape = (vector.shape[1],vector.shape[2]))\n",
        "  ##Block1##\n",
        "  hidden = layers.Conv1D(16, 3) (inputs_vector)\n",
        "  hidden = layers.Activation('tanh')(hidden)\n",
        "  hidden = layers.BatchNormalization()(hidden)\n",
        "  hidden = layers.Conv1D(16, 3)(hidden)\n",
        "  hidden = layers.Activation('relu')(hidden)\n",
        "  hidden = layers.BatchNormalization()(hidden)\n",
        "  hidden = layers.MaxPooling1D(hidden)\n",
        "\n",
        "  out_class = layers.Flatten()(hidden)\n",
        "\n",
        "  out_class = layers.Dense(56, activation = 'relu')(out_class)\n",
        "  out_class = layers.Dense(1, activation = 'sigmoid')(out_class)\n",
        "\n",
        "  ##Block2##\n",
        "  hidden = layers.Conv1D(64, 3) (hidden)\n",
        "  hidden = layers.Activation('tanh')(hidden)\n",
        "  hidden = layers.BatchNormalization()(hidden)\n",
        "  hidden = layers.Conv1D(64, 3)(hidden)\n",
        "  hidden = layers.Activation('relu')(hidden)\n",
        "  hidden = layers.BatchNormalization()(hidden)\n",
        "  hidden = layers.MaxPooling1D(hidden)\n",
        "\n",
        "  \n",
        "  ##Block3##\n",
        "  #hidden = Conv1D(128, 3) (hidden)\n",
        "  #hidden = Activation('tanh')\n",
        "  #hidden = BatchNormalization()(hidden)\n",
        "  #hidden = Conv1D(128, 3)(hidden)\n",
        "  #hidden = Activation('relu')\n",
        "  #hidden = BatchNormalization()(hidden)\n",
        "  #hidden = MaxPooling1D(hidden)  \n",
        "\n",
        "  ##UPBlock1##\n",
        "  hidden = layers.UpSampling1D(hidden)\n",
        "  hidden = layers.Conv1D(64, 3, activation= 'relu')(hidden)\n",
        "  hidden = layers.BatchNormalization()(hidden)\n",
        "  \n",
        "  ##UPblock2\n",
        "  hidden = layers.UpSampling1D(hidden)\n",
        "  hidden = layers.Conv1D(16, 3, activation= 'relu')(hidden)\n",
        "  hidden = layers.BatchNormalization()(hidden)\n",
        "\n",
        "  hidden = layers.Flatten()(hidden)\n",
        "  hidden = layers.Concatenate([out_class, hidden])\n",
        "  hidden = layers.Dense(128, activation='relu')(hidden)\n",
        "  out = layers.Dense(inputs_vector.size)(hidden)\n",
        "\n",
        "  modelD = Model(inputs=inputs_vector, outputs = out)\n",
        "\n",
        "  return modelD\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDm1EtKtVhlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle(a, b):\n",
        "    p = np.random.permutation(len(a)) \n",
        "    return a[p], b[p] \n",
        "\n",
        "x_train_, y_train_ = shuffle(x_train, y_train)\n",
        "x_val_, y_val_ = shuffle(x_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daZg86xp2D_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8bee1ac-a1fc-4254-a140-4cbd35c6c7ea"
      },
      "source": [
        "classificator = classificator(clean_arrays)\n",
        "classificator.compile(optimizer = RMSprop(), loss = 'mse', metrics = 'accuracy')\n",
        "classificator.fit(x_train_, y_train_, batch_size=100, epochs=20, validation_data=x_val_, y_val_)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJB_8QMVGLje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "denoise, result = autoencoder(classificator, clean_arrays_)\n",
        "denoise.compile(optimizer = RMSprop(), loss = 'mse', metrics = 'accuracy')\n",
        "denoise.fit([result, clean_arrays], clean_arrays)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds_tXun7VYJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "denoise.predict([])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}